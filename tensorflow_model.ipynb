{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from random import sample\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, split, and normalize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_evalmetrics_df():\n",
    "    return pd.read_pickle(path.join('.', 'raw_evalmetrics_df.pkl'))\n",
    "\n",
    "def prep_multivarate(df):\n",
    "    \"\"\" Calculates density and removes unnecessary columns \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df['density'] = df.latestTotalPopulation / df.LND110210\n",
    "    new_df = new_df.drop(columns=['latestTotalPopulation','fips','LND110210'])\n",
    "    return new_df\n",
    "\n",
    "def split_sample(df, percent_train=.80):\n",
    "    county = set(df.county)\n",
    "    train_county = sample(county, int(len(county) * percent_train))\n",
    "    val_county = county - set(train_county)\n",
    "    train_filter = [c in train_county for c in df.county]\n",
    "    val_filter = [c in val_county for c in df.county]\n",
    "    return df[train_filter].fillna(0), df[val_filter].fillna(0)\n",
    "\n",
    "def normalize_df(df):\n",
    "    new_df = df.copy()\n",
    "    cols = ['confirmed_cases','confirmed_deaths', 'confirmed_recoveries','hospitalIcuBeds','hospitalStaffedBeds','hospitalLicensedBeds', 'density']\n",
    "    for col in cols:\n",
    "        data = new_df[col].astype('float')\n",
    "        data_mean = data.mean(axis=0)\n",
    "        data_std = data.std(axis=0)\n",
    "        new_df[col] = (data-data_mean)/data_std\n",
    "    return new_df.fillna(0)\n",
    "\n",
    "def get_data():\n",
    "    evalmetric_df = load_raw_evalmetrics_df()\n",
    "    prepped_df = prep_multivarate(evalmetric_df)\n",
    "    train_df, val_df = split_sample(prepped_df)\n",
    "    return normalize_df(train_df), val_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the data for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "\n",
    "def multivariate_data(dataset, target_col, history_size=20, target_size=0):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    counties = set(dataset.county)\n",
    "    \n",
    "    for j, county in enumerate(counties):\n",
    "        if (j + 1) % 100 == 0:\n",
    "            print('.', end='')\n",
    "        sub_dataset = dataset[dataset.county == county]\n",
    "        target = sub_dataset[target_col].values\n",
    "        sub_dataset = sub_dataset.values\n",
    "        start_index = history_size\n",
    "        end_index = len(sub_dataset) - target_size\n",
    "\n",
    "        for i in range(start_index, end_index):\n",
    "            indices = range(i-history_size, i)\n",
    "            data.append(sub_dataset[indices])\n",
    "\n",
    "            labels.append(target[i+target_size])\n",
    "\n",
    "    print()\n",
    "    return np.array(data), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = get_data()\n",
    "train_data, train_labels = multivariate_data(train_df, 'confirmed_deaths')\n",
    "val_data, val_labels = multivariate_data(val_df, 'confirmed_deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 720\n",
    "future_target = 72\n",
    "STEP = 6\n",
    "\n",
    "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 1], 0,\n",
    "                                                   TRAIN_SPLIT, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=True)\n",
    "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 1],\n",
    "                                               TRAIN_SPLIT, None, past_history,\n",
    "                                               future_target, STEP,\n",
    "                                               single_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed_cases</th>\n",
       "      <th>confirmed_deaths</th>\n",
       "      <th>confirmed_recoveries</th>\n",
       "      <th>hospitalIcuBeds</th>\n",
       "      <th>hospitalStaffedBeds</th>\n",
       "      <th>hospitalLicensedBeds</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333648</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>-0.066651</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333649</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>-0.066651</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333650</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>-0.066651</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333651</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>-0.066651</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333652</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>-0.066651</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333787</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.040878</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333788</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.040878</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333789</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.040878</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333790</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.040878</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333791</th>\n",
       "      <td>Pike_Kentucky_UnitedStates</td>\n",
       "      <td>2020-05-23</td>\n",
       "      <td>-0.062216</td>\n",
       "      <td>-0.040878</td>\n",
       "      <td>-0.033007</td>\n",
       "      <td>0.64039</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>-0.157574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            county        date  confirmed_cases  \\\n",
       "333648  Pike_Kentucky_UnitedStates  2020-01-01        -0.066651   \n",
       "333649  Pike_Kentucky_UnitedStates  2020-01-02        -0.066651   \n",
       "333650  Pike_Kentucky_UnitedStates  2020-01-03        -0.066651   \n",
       "333651  Pike_Kentucky_UnitedStates  2020-01-04        -0.066651   \n",
       "333652  Pike_Kentucky_UnitedStates  2020-01-05        -0.066651   \n",
       "...                            ...         ...              ...   \n",
       "333787  Pike_Kentucky_UnitedStates  2020-05-19        -0.062216   \n",
       "333788  Pike_Kentucky_UnitedStates  2020-05-20        -0.062216   \n",
       "333789  Pike_Kentucky_UnitedStates  2020-05-21        -0.062216   \n",
       "333790  Pike_Kentucky_UnitedStates  2020-05-22        -0.062216   \n",
       "333791  Pike_Kentucky_UnitedStates  2020-05-23        -0.062216   \n",
       "\n",
       "        confirmed_deaths  confirmed_recoveries  hospitalIcuBeds  \\\n",
       "333648         -0.045146             -0.033007          0.64039   \n",
       "333649         -0.045146             -0.033007          0.64039   \n",
       "333650         -0.045146             -0.033007          0.64039   \n",
       "333651         -0.045146             -0.033007          0.64039   \n",
       "333652         -0.045146             -0.033007          0.64039   \n",
       "...                  ...                   ...              ...   \n",
       "333787         -0.040878             -0.033007          0.64039   \n",
       "333788         -0.040878             -0.033007          0.64039   \n",
       "333789         -0.040878             -0.033007          0.64039   \n",
       "333790         -0.040878             -0.033007          0.64039   \n",
       "333791         -0.040878             -0.033007          0.64039   \n",
       "\n",
       "        hospitalStaffedBeds  hospitalLicensedBeds   density  \n",
       "333648             0.178098              0.217083 -0.157574  \n",
       "333649             0.178098              0.217083 -0.157574  \n",
       "333650             0.178098              0.217083 -0.157574  \n",
       "333651             0.178098              0.217083 -0.157574  \n",
       "333652             0.178098              0.217083 -0.157574  \n",
       "...                     ...                   ...       ...  \n",
       "333787             0.178098              0.217083 -0.157574  \n",
       "333788             0.178098              0.217083 -0.157574  \n",
       "333789             0.178098              0.217083 -0.157574  \n",
       "333790             0.178098              0.217083 -0.157574  \n",
       "333791             0.178098              0.217083 -0.157574  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#train_df, val_df = get_data()\n",
    "train_df\n",
    "sds = train_df[train_df.county == 'Pike_Kentucky_UnitedStates']\n",
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.confirmed_cases.astype('float')\n",
    "\n",
    "data_mean = data.mean(axis=0)\n",
    "data_std = data.std(axis=0)\n",
    "data = (data-data_mean)/data_std\n",
    "print(round(data.mean(axis=0),10))\n",
    "print(round(data.std(axis=0),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
