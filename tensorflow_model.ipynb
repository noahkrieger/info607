{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from random import sample\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "EVALUATION_INTERVAL = 1000\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, split, and normalize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_evalmetrics_df():\n",
    "    return pd.read_pickle(path.join('.', 'raw_evalmetrics_df.pkl'))\n",
    "\n",
    "def prep_multivarate(df):\n",
    "    \"\"\" Calculates density and removes unnecessary columns \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df['density'] = df.latestTotalPopulation / df.LND110210\n",
    "    new_df = new_df.drop(columns=['latestTotalPopulation','fips','LND110210'])\n",
    "    return new_df\n",
    "\n",
    "def split_sample(df, percent_train=.80):\n",
    "    county = set(df.county)\n",
    "    train_county = sample(county, int(len(county) * percent_train))\n",
    "    val_county = county - set(train_county)\n",
    "    train_filter = [c in train_county for c in df.county]\n",
    "    val_filter = [c in val_county for c in df.county]\n",
    "    return df[train_filter].fillna(0), df[val_filter].fillna(0)\n",
    "\n",
    "def normalize_df(train_df, val_df):\n",
    "    new_train_df = train_df.copy()\n",
    "    new_val_df = val_df.copy()\n",
    "    cols = ['confirmed_cases','confirmed_deaths', 'confirmed_recoveries','hospitalIcuBeds','hospitalStaffedBeds','hospitalLicensedBeds', 'density']\n",
    "    for col in cols:\n",
    "        # calculate mean and std on training data only\n",
    "        data = new_train_df[col].astype('float')\n",
    "        data_mean = data.mean(axis=0)\n",
    "        data_std = data.std(axis=0)\n",
    "        new_train_df[col] = (data-data_mean)/data_std\n",
    "        #apply to val data\n",
    "        data = new_val_df[col].astype('float')\n",
    "        new_val_df[col] = (data-data_mean)/data_std\n",
    "    return new_train_df.fillna(0), new_val_df.fillna(0)\n",
    "\n",
    "def get_data():\n",
    "    evalmetric_df = load_raw_evalmetrics_df()\n",
    "    prepped_df = prep_multivarate(evalmetric_df)\n",
    "    train_df, val_df = split_sample(prepped_df)\n",
    "    return normalize_df(train_df, val_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the data for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "\n",
    "def multivariate_data(dataset, target_col, history_size=20, target_size=0):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    counties = set(dataset.county)\n",
    "    \n",
    "    for j, county in enumerate(counties):\n",
    "        if (j + 1) % 100 == 0:\n",
    "            print('.', end='')\n",
    "        sub_dataset = dataset[dataset.county == county]\n",
    "        target = sub_dataset[target_col].values\n",
    "        sub_dataset = sub_dataset.drop(columns=['county', 'date'])\n",
    "        sub_dataset = sub_dataset.values\n",
    "        start_index = history_size\n",
    "        end_index = len(sub_dataset) - target_size\n",
    "\n",
    "        for i in range(start_index, end_index):\n",
    "            indices = range(i-history_size, i)\n",
    "            data.append(sub_dataset[indices])\n",
    "\n",
    "            labels.append(target[i+target_size])\n",
    "\n",
    "    print()\n",
    "    return np.array(data), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_cache_for_tensorflow(x_train, y_train, x_val, y_val):\n",
    "    x_train = np.asarray(x_train).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "    x_val = np.asarray(x_val).astype(np.float32)\n",
    "    y_val = np.asarray(y_val).astype(np.float32)\n",
    "    val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    val_data = val_data.batch(BATCH_SIZE).repeat()\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "def build_and_compile_model(x_train):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(32, input_shape=x_train.shape[-2:]))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "    return model\n",
    "\n",
    "def fit_model(model, train_data, val_data):\n",
    "    history = model.fit(train_data, epochs=EPOCHS,\n",
    "                            steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                            validation_data=val_data,\n",
    "                            validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "......\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0271 - val_loss: 0.0129\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0300 - val_loss: 0.0051\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0259 - val_loss: 0.0046\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0222 - val_loss: 0.0032\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0241 - val_loss: 0.0034\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0185 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0195 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0242 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0178 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0156 - val_loss: 0.0031\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = get_data()\n",
    "x_train, y_train = multivariate_data(train_df, 'confirmed_deaths')\n",
    "x_val, y_val = multivariate_data(val_df, 'confirmed_deaths')\n",
    "\n",
    "train_data, val_data = slice_cache_for_tensorflow(x_train, y_train, x_val, y_val)\n",
    "model = build_and_compile_model(x_train)\n",
    "history = fit_model(model, train_data, val_data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
